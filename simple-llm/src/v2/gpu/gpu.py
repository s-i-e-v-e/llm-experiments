"""
GPU (WGPU) Backend for LLM Training and Inference
"""

from .gpu_buffer import (
    create_gpu_buffer_1d,
    create_gpu_buffer_2d,
    pool_clear,
    pool_create,
    pool_release_buffer,
    pool_take_buffer_1d,
    pool_take_buffer_2d,
    staging_pool_create,
    staging_pool_download,
    staging_pool_upload,
)
from .gpu_device import (
    device_config_auto_detect,
    device_config_create,
    device_config_init,
    device_config_shared_memory_usage_estimate,
    device_config_validate,
    device_create,
    device_limits_query,
    perf_monitor_create,
    perf_monitor_kernel_time_record,
    perf_monitor_reset,
    perf_monitor_stats_get,
    perf_monitor_submission_record,
    pipeline_cache_create,
    pipeline_get_or_create,
    pipeline_tuned_create,
    select_optimal_tile_size,
)
from .gpu_operations import (
    # Optimizer
    adamw_step,
    attention,
    attention_backward,
    bias_add,
    bias_backward,
    # Infrastructure
    create_batch_state,
    cross_entropy_loss,
    embedding,
    gelu,
    gelu_backward,
    layernorm,
    layernorm_backward,
    layernorm_backward_reduce,
    # Forward ops
    matmul,
    # Backward ops
    matmul_backward_a,
    matmul_backward_b,
    residual_add,
    submit_batch,
)
from .gpu_types import (
    BatchState,
    Device,
    GPUBuffer1D,
    GPUBuffer2D,
    GPUBuffer3D,
    GPUConfig,
    GPULayerParams,
    GPUModelParams,
    GPUOptimizerState,
    PipelineCache,
    WorkspaceBuffers,
    WorkspaceManager,
)
from .gpu_workspace import (
    workspace_all_release,
    workspace_get_or_create,
    workspace_lru_release,
    workspace_manager_create,
    workspace_memory_usage_get,
    workspace_release,
)

__all__ = [
    # Types
    "Device",
    "GPUConfig",
    "GPUBuffer1D",
    "GPUBuffer2D",
    "GPUBuffer3D",
    "GPUModelParams",
    "GPULayerParams",
    "GPUOptimizerState",
    "BatchState",
    "PipelineCache",
    "WorkspaceBuffers",
    "WorkspaceManager",
    # Device
    "device_create",
    "device_limits_query",
    "pipeline_cache_create",
    "pipeline_get_or_create",
    "pipeline_tuned_create",
    "select_optimal_tile_size",
    "device_config_create",
    "device_config_init",
    "device_config_validate",
    "device_config_auto_detect",
    "device_config_shared_memory_usage_estimate",
    # Buffers
    "create_gpu_buffer_1d",
    "create_gpu_buffer_2d",
    "staging_pool_create",
    "staging_pool_upload",
    "staging_pool_download",
    "pool_create",
    "pool_take_buffer_1d",
    "pool_take_buffer_2d",
    "pool_release_buffer",
    "pool_clear",
    # Workspace
    "workspace_manager_create",
    "workspace_get_or_create",
    "workspace_release",
    "workspace_all_release",
    "workspace_lru_release",
    "workspace_memory_usage_get",
    # Operations
    "create_batch_state",
    "submit_batch",
    "matmul",
    "embedding",
    "attention",
    "layernorm",
    "gelu",
    "bias_add",
    "residual_add",
    "cross_entropy_loss",
    "matmul_backward_a",
    "matmul_backward_b",
    "layernorm_backward",
    "layernorm_backward_reduce",
    "gelu_backward",
    "bias_backward",
    "attention_backward",
    # Optimizer
    "adamw_step",
    # Profiling
    "perf_monitor_reset",
    "perf_monitor_stats_get",
    "perf_monitor_submission_record",
    "perf_monitor_kernel_time_record",
    "perf_monitor_create",
]
